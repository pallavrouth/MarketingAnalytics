{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNC3lyhW/vqGhlWFroNRDhf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pallavrouth/MarketingAnalytics/blob/main/Data_wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is data wrangling?\n",
        "\n",
        "Data wrangling, also known as data munging or data preprocessing, refers to the process of cleaning, transforming, and organizing raw and messy data into a structured and usable format for analysis and modeling.\n",
        "\n",
        "It is a crucial step in the data analysis pipeline as it ensures that the data is accurate, consistent, and properly formatted before any meaningful insights can be extracted from it.\n",
        "\n",
        "# What does it include?\n",
        "\n",
        "**Data Collection:** Gather raw data from various sources, such as databases, files, APIs, or web scraping.\n",
        "\n",
        "**Data Inspection**: Explore the data to understand its structure, format, and potential issues. Identify missing values, outliers, and inconsistencies.\n",
        "\n",
        "**Data Cleaning:** Address data quality issues by handling missing values, correcting errors, and dealing with outliers. This may involve imputing missing values and removing duplicates\n",
        "\n",
        "**Data Transformation:** This may include changing the shape of the data or converting the data types, creating new variables, aggregating data, and creating new features.\n",
        "\n",
        "**Data Enrichment:** Enhance the dataset by adding relevant information from external sources or combining multiple datasets to gain more insights.\n",
        "\n",
        "Tools and libraries such as Python's Pandas, NumPy, and scikit-learn are commonly used for data wrangling tasks, as they provide powerful functionalities for data manipulation, cleaning, and transformation."
      ],
      "metadata": {
        "id": "gRWiCmTI4Q8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas\n",
        "\n",
        "Pandas is a popular open-source Python library used for data manipulation and analysis. It provides data structures and functions that make it easier to work with structured, tabular, and time-series data."
      ],
      "metadata": {
        "id": "jls83EC74WrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "EY9_P2Eo6z48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data structures\n",
        "\n",
        "Pandas **Series** and **DataFrames** are two fundamental data structures provided by the Pandas library for handling and manipulating data in Python. They are designed to work with tabular and labeled data, making it easier to perform various data analysis and manipulation tasks."
      ],
      "metadata": {
        "id": "RSHMQZ9a6VGr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1P6eXFf4GWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7333bb-de4f-494e-860f-5df273ce17a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice      30\n",
            "Bob        25\n",
            "Charlie    28\n",
            "David      22\n",
            "Eve        35\n",
            "dtype: int64\n",
            "Alice      30\n",
            "Bob        25\n",
            "Charlie    28\n",
            "David      22\n",
            "Eve        35\n",
            "dtype: int64\n",
            "<class 'pandas.core.series.Series'>\n",
            "      Name  Age    Country  PurchaseAmount\n",
            "0    Alice   30        USA             100\n",
            "1      Bob   25     Canada              50\n",
            "2  Charlie   28         UK              80\n",
            "3    David   22  Australia             120\n",
            "4      Eve   35        USA              90\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "# series - is a one-dimensional labeled array capable of holding any data type\n",
        "# (integers, strings, floating point numbers, Python objects\n",
        "customer_ages_array = pd.Series([30, 25, 28, 22, 35], index = ['Alice', 'Bob', 'Charlie', 'David', 'Eve'])\n",
        "customer_ages_dict = pd.Series({'Alice':30, 'Bob': 25, 'Charlie': 28, 'David': 22, 'Eve': 35})\n",
        "print(customer_ages_array)\n",
        "print(customer_ages_dict)\n",
        "print(type(customer_ages_dict))\n",
        "\n",
        "# dataframe - 2-dimensional labeled data structure with columns of potentially different types.\n",
        "# You can think of it like a spreadsheet or SQL table, or a dict of Series objects.\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'Age': [30, 25, 28, 22, 35],\n",
        "    'Country': ['USA', 'Canada', 'UK', 'Australia', 'USA'],\n",
        "    'PurchaseAmount': [100, 50, 80, 120, 90]\n",
        "}\n",
        "\n",
        "customer_data = pd.DataFrame(data)\n",
        "print(customer_data)\n",
        "print(type(customer_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Special types of variables\n",
        "\n",
        "1. **Date time variables:** Pandas has robust support for working with datetime data. It includes specialized datetime-related data structures like Timestamp and DatetimeIndex. These allow for easy manipulation and alignment of time-based data, enabling time series analysis.\n",
        "\n",
        "2. **Factor (categorical variables):** Categorical variables represent data that has a limited, fixed number of unique values (categories). Using categorical data types in pandas can optimize memory usage and improve performance, especially when dealing with large datasets. Categorical variables are also useful for maintaining a fixed set of labels and managing categorical data efficiently."
      ],
      "metadata": {
        "id": "N2hP657Z3PFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a datetime object\n",
        "date_time = pd.to_datetime(\"2023-10-02 15:30:00\")\n",
        "\n",
        "# Extracting components of the datetime\n",
        "year = date_time.year\n",
        "month = date_time.month\n",
        "day = date_time.day\n",
        "hour = date_time.hour\n",
        "minute = date_time.minute\n",
        "second = date_time.second\n",
        "\n",
        "print(date_time)\n",
        "print(year, month, day, hour, minute, second)\n",
        "\n",
        "# Creating two datetime objects\n",
        "start_time = pd.to_datetime(\"2023-10-02 10:00:00\")\n",
        "end_time = pd.to_datetime(\"2023-10-03 12:30:00\")\n",
        "\n",
        "# Calculating the time duration between two datetime objects\n",
        "duration = end_time - start_time\n",
        "\n",
        "print(duration)\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
        "    'Education': ['High School', 'College', 'High School', 'PhD', 'College']\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert 'Gender' column to a categorical variable\n",
        "df['Gender'] = pd.Categorical(df['Gender'], categories = ['Male', 'Female'], ordered=False)\n",
        "\n",
        "# Convert 'Education' column to a categorical variable\n",
        "df['Education'] = pd.Categorical(df['Education'], categories = ['High School', 'College', 'PhD'], ordered=True)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "-UH4188GSAdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this course we will mainly deal with dataframes. Also we will mostly import datasets instead of creating them.\n",
        "\n",
        "# Importing data\n",
        "\n",
        "Pandas provides import functions for variety of file types. In this course we will mainly deal with csv files and sometimes with excel files. For csv we use `read_csv()` and for excel we use `read_excel()` function.\n",
        "\n"
      ],
      "metadata": {
        "id": "ppNi6UOmCF_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# file path\n",
        "file_path = \"https://raw.githubusercontent.com/pallavrouth/MarketingAnalytics/main/datasets/transaction_transactions.csv\"\n",
        "\n",
        "# read the CSV file into a DataFrame\n",
        "transactions = pd.read_csv(file_path, index_col = False)\n",
        "print(transactions.head())\n",
        "\n",
        "# to specify a particular column as index\n",
        "transactions_withid = pd.read_csv(file_path, index_col = 'customer_id')\n",
        "print(transactions_withid.head())"
      ],
      "metadata": {
        "id": "8qhYsuaHIc3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b921ef-fedd-44dc-8007-ec99645ff771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   transaction_id  product_id  customer_id transaction_date online_order  \\\n",
            "0               1           2         2950       25/02/2017        False   \n",
            "1               2           3         3120       21/05/2017         True   \n",
            "2               3          37          402       16/10/2017        False   \n",
            "3               4          88         3135       31/08/2017        False   \n",
            "4               5          78          787       01/10/2017         True   \n",
            "\n",
            "  order_status           brand product_line product_class product_size  \\\n",
            "0     Approved           Solex     Standard        medium       medium   \n",
            "1     Approved   Trek Bicycles     Standard        medium        large   \n",
            "2     Approved      OHM Cycles     Standard           low       medium   \n",
            "3     Approved  Norco Bicycles     Standard        medium       medium   \n",
            "4     Approved  Giant Bicycles     Standard        medium        large   \n",
            "\n",
            "   list_price standard_cost  product_first_sold_date  \n",
            "0       71.49        $53.62                  41245.0  \n",
            "1     2091.47       $388.92                  41701.0  \n",
            "2     1793.43       $248.82                  36361.0  \n",
            "3     1198.46       $381.10                  36145.0  \n",
            "4     1765.30       $709.48                  42226.0  \n",
            "             transaction_id  product_id transaction_date online_order  \\\n",
            "customer_id                                                             \n",
            "2950                      1           2       25/02/2017        False   \n",
            "3120                      2           3       21/05/2017         True   \n",
            "402                       3          37       16/10/2017        False   \n",
            "3135                      4          88       31/08/2017        False   \n",
            "787                       5          78       01/10/2017         True   \n",
            "\n",
            "            order_status           brand product_line product_class  \\\n",
            "customer_id                                                           \n",
            "2950            Approved           Solex     Standard        medium   \n",
            "3120            Approved   Trek Bicycles     Standard        medium   \n",
            "402             Approved      OHM Cycles     Standard           low   \n",
            "3135            Approved  Norco Bicycles     Standard        medium   \n",
            "787             Approved  Giant Bicycles     Standard        medium   \n",
            "\n",
            "            product_size  list_price standard_cost  product_first_sold_date  \n",
            "customer_id                                                                  \n",
            "2950              medium       71.49        $53.62                  41245.0  \n",
            "3120               large     2091.47       $388.92                  41701.0  \n",
            "402               medium     1793.43       $248.82                  36361.0  \n",
            "3135              medium     1198.46       $381.10                  36145.0  \n",
            "787                large     1765.30       $709.48                  42226.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, when importing pandas creates an index column. We can avoid this by setting `index_col = 0`\n",
        "\n",
        "# Inspecting the data\n",
        "\n",
        "After importing the dataset, the first task is to inspect the data. Inspection of the data involves\n",
        "\n",
        "1. understanding the dimensions of the data,\n",
        "2. understanding the data types for each column\n",
        "3. understanding whether there are problems/issues with the data (for example, presence of missing values)"
      ],
      "metadata": {
        "id": "p6bgoEKGLuW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get a sneak peak into the data\n",
        "print(transactions.head(), '\\n') # alternatively use tail()\n",
        "\n",
        "# get a sense of the dimensions of the data\n",
        "print(transactions.shape, '\\n')\n",
        "\n",
        "# get all the names of columns\n",
        "print(transactions.columns, '\\n')\n",
        "\n",
        "# get the attributes of all the columns\n",
        "print(transactions.dtypes, '\\n')\n",
        "\n",
        "# get a concise summary\n",
        "print(transactions.info(), '\\n')\n",
        "\n",
        "# get a count of missing values\n",
        "print(transactions.isnull().sum(), '\\n')\n",
        "\n",
        "# more inspection\n",
        "print(transactions['product_class'].unique(), '\\n')\n",
        "print(transactions['product_class'].nunique(), '\\n')\n",
        "\n",
        "# get descriptive statistics\n",
        "print(transactions.describe(), '\\n')"
      ],
      "metadata": {
        "id": "iCkASW5VNjH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5653a04-6699-4d3f-dc88-9a8beb846ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   transaction_id  product_id  customer_id transaction_date online_order  \\\n",
            "0               1           2         2950       25/02/2017        False   \n",
            "1               2           3         3120       21/05/2017         True   \n",
            "2               3          37          402       16/10/2017        False   \n",
            "3               4          88         3135       31/08/2017        False   \n",
            "4               5          78          787       01/10/2017         True   \n",
            "\n",
            "  order_status           brand product_line product_class product_size  \\\n",
            "0     Approved           Solex     Standard        medium       medium   \n",
            "1     Approved   Trek Bicycles     Standard        medium        large   \n",
            "2     Approved      OHM Cycles     Standard           low       medium   \n",
            "3     Approved  Norco Bicycles     Standard        medium       medium   \n",
            "4     Approved  Giant Bicycles     Standard        medium        large   \n",
            "\n",
            "   list_price standard_cost  product_first_sold_date  \n",
            "0       71.49        $53.62                  41245.0  \n",
            "1     2091.47       $388.92                  41701.0  \n",
            "2     1793.43       $248.82                  36361.0  \n",
            "3     1198.46       $381.10                  36145.0  \n",
            "4     1765.30       $709.48                  42226.0   \n",
            "\n",
            "(20000, 13) \n",
            "\n",
            "Index(['transaction_id', 'product_id', 'customer_id', 'transaction_date',\n",
            "       'online_order', 'order_status', 'brand', 'product_line',\n",
            "       'product_class', 'product_size', 'list_price', 'standard_cost',\n",
            "       'product_first_sold_date'],\n",
            "      dtype='object') \n",
            "\n",
            "transaction_id               int64\n",
            "product_id                   int64\n",
            "customer_id                  int64\n",
            "transaction_date            object\n",
            "online_order                object\n",
            "order_status                object\n",
            "brand                       object\n",
            "product_line                object\n",
            "product_class               object\n",
            "product_size                object\n",
            "list_price                 float64\n",
            "standard_cost               object\n",
            "product_first_sold_date    float64\n",
            "dtype: object \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 13 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   transaction_id           20000 non-null  int64  \n",
            " 1   product_id               20000 non-null  int64  \n",
            " 2   customer_id              20000 non-null  int64  \n",
            " 3   transaction_date         20000 non-null  object \n",
            " 4   online_order             19640 non-null  object \n",
            " 5   order_status             20000 non-null  object \n",
            " 6   brand                    19803 non-null  object \n",
            " 7   product_line             19803 non-null  object \n",
            " 8   product_class            19803 non-null  object \n",
            " 9   product_size             19803 non-null  object \n",
            " 10  list_price               20000 non-null  float64\n",
            " 11  standard_cost            19803 non-null  object \n",
            " 12  product_first_sold_date  19803 non-null  float64\n",
            "dtypes: float64(2), int64(3), object(8)\n",
            "memory usage: 2.0+ MB\n",
            "None \n",
            "\n",
            "transaction_id               0\n",
            "product_id                   0\n",
            "customer_id                  0\n",
            "transaction_date             0\n",
            "online_order               360\n",
            "order_status                 0\n",
            "brand                      197\n",
            "product_line               197\n",
            "product_class              197\n",
            "product_size               197\n",
            "list_price                   0\n",
            "standard_cost              197\n",
            "product_first_sold_date    197\n",
            "dtype: int64 \n",
            "\n",
            "['medium' 'low' 'high' nan] \n",
            "\n",
            "3 \n",
            "\n",
            "       transaction_id   product_id   customer_id    list_price  \\\n",
            "count    20000.000000  20000.00000  20000.000000  20000.000000   \n",
            "mean     10000.500000     45.36465   1738.246050   1107.829449   \n",
            "std       5773.647028     30.75359   1011.951046    582.825242   \n",
            "min          1.000000      0.00000      1.000000     12.010000   \n",
            "25%       5000.750000     18.00000    857.750000    575.270000   \n",
            "50%      10000.500000     44.00000   1736.000000   1163.890000   \n",
            "75%      15000.250000     72.00000   2613.000000   1635.300000   \n",
            "max      20000.000000    100.00000   5034.000000   2091.470000   \n",
            "\n",
            "       product_first_sold_date  \n",
            "count             19803.000000  \n",
            "mean              38199.776549  \n",
            "std                2875.201110  \n",
            "min               33259.000000  \n",
            "25%               35667.000000  \n",
            "50%               38216.000000  \n",
            "75%               40672.000000  \n",
            "max               42710.000000   \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning\n",
        "\n",
        "At this stage it makes sense to correct any issues or errors that are there in the data. Addressing data issues early can make sure important operations such as creating new columns or merging datasets produce expected results. Some of the most common data cleaning steps include -\n",
        "\n",
        "1. Addressing the presence of missing values\n",
        "2. Addressing the presence of duplicated information in the dataframe\n",
        "3. Renaming columns"
      ],
      "metadata": {
        "id": "5lEt3Uu1V2FM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dealing with missing values\n",
        "\n",
        "One of the most prevalent issues present in marketing datasets are missing values. These are present either due to lack of information for specific rows or due to errors in record keeping. Before attempting to manipuate data, it is crucial to come up with a strategy to deal with missing data."
      ],
      "metadata": {
        "id": "H7H0CS9pr0Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'A': [   1, 2, None, 4],\n",
        "        'B': [None, 5,    6, 7],\n",
        "        'C': [  10, 9,    1, 0]}\n",
        "df = pd.DataFrame(data)\n",
        "print(df,'\\n')\n",
        "\n",
        "# detect missing values\n",
        "print(df.isnull().sum(),'\\n')\n",
        "\n",
        "# total count\n",
        "print(df.isnull().sum().sum(),'\\n')\n",
        "\n",
        "# non null values\n",
        "print(df.notnull().sum(),'\\n')\n",
        "\n",
        "# removing rows with missing values for all columns\n",
        "print(df.dropna(axis = 0),'\\n')\n",
        "# removing columns that has any missing values\n",
        "print(df.dropna(axis = 1),'\\n')\n",
        "\n",
        "# removing rows with missing values for a specific column\n",
        "print(df.dropna(axis = 0, subset = [\"A\"]),'\\n')\n",
        "\n",
        "# removing columns that have a high proportion of missing values\n",
        "# df.dropna(axis = 1, thresh = len(df) * 0.8)\n",
        "\n",
        "# filling all missing values with 0 or with mean values\n",
        "print(df.fillna(0),'\\n')\n",
        "print(df.fillna(df.mean()),'\\n')\n",
        "\n",
        "# filling all missing values with the value before or after null\n",
        "print(df.fillna(method = 'ffill'),'\\n')\n",
        "print(df.fillna(method = 'bfill'),'\\n')\n",
        "\n",
        "# specific values for specific columns\n",
        "values = {'A': 2.0, 'B': 5.0}\n",
        "print(df.fillna(value = values),'\\n')\n",
        "\n",
        "# applying this to our dataset\n",
        "transactions_nonnull = transactions.dropna(axis = 0)\n",
        "print(transactions_nonnull.info(),'\\n')"
      ],
      "metadata": {
        "id": "BXmiOaYCV1o-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c521b0-c4cf-4063-8195-2978f3a5ea84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A    B   C\n",
            "0  1.0  NaN  10\n",
            "1  2.0  5.0   9\n",
            "2  NaN  6.0   1\n",
            "3  4.0  7.0   0 \n",
            "\n",
            "A    1\n",
            "B    1\n",
            "C    0\n",
            "dtype: int64 \n",
            "\n",
            "2 \n",
            "\n",
            "A    3\n",
            "B    3\n",
            "C    4\n",
            "dtype: int64 \n",
            "\n",
            "     A    B  C\n",
            "1  2.0  5.0  9\n",
            "3  4.0  7.0  0 \n",
            "\n",
            "    C\n",
            "0  10\n",
            "1   9\n",
            "2   1\n",
            "3   0 \n",
            "\n",
            "     A    B   C\n",
            "0  1.0  NaN  10\n",
            "1  2.0  5.0   9\n",
            "3  4.0  7.0   0 \n",
            "\n",
            "     A    B   C\n",
            "0  1.0  0.0  10\n",
            "1  2.0  5.0   9\n",
            "2  0.0  6.0   1\n",
            "3  4.0  7.0   0 \n",
            "\n",
            "          A    B   C\n",
            "0  1.000000  6.0  10\n",
            "1  2.000000  5.0   9\n",
            "2  2.333333  6.0   1\n",
            "3  4.000000  7.0   0 \n",
            "\n",
            "     A    B   C\n",
            "0  1.0  NaN  10\n",
            "1  2.0  5.0   9\n",
            "2  2.0  6.0   1\n",
            "3  4.0  7.0   0 \n",
            "\n",
            "     A    B   C\n",
            "0  1.0  5.0  10\n",
            "1  2.0  5.0   9\n",
            "2  4.0  6.0   1\n",
            "3  4.0  7.0   0 \n",
            "\n",
            "     A    B   C\n",
            "0  1.0  5.0  10\n",
            "1  2.0  5.0   9\n",
            "2  2.0  6.0   1\n",
            "3  4.0  7.0   0 \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 19445 entries, 0 to 19999\n",
            "Data columns (total 13 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   transaction_id           19445 non-null  int64  \n",
            " 1   product_id               19445 non-null  int64  \n",
            " 2   customer_id              19445 non-null  int64  \n",
            " 3   transaction_date         19445 non-null  object \n",
            " 4   online_order             19445 non-null  object \n",
            " 5   order_status             19445 non-null  object \n",
            " 6   brand                    19445 non-null  object \n",
            " 7   product_line             19445 non-null  object \n",
            " 8   product_class            19445 non-null  object \n",
            " 9   product_size             19445 non-null  object \n",
            " 10  list_price               19445 non-null  float64\n",
            " 11  standard_cost            19445 non-null  object \n",
            " 12  product_first_sold_date  19445 non-null  float64\n",
            "dtypes: float64(2), int64(3), object(8)\n",
            "memory usage: 2.1+ MB\n",
            "None \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dealing with duplications\n",
        "\n",
        "Another common issue with data is the presence of duplicates. Sometimes duplicates are created because of inaccuracies in data recording or after merging data with another datasets. It is important to constantly check for the presence of duplicate rows because it can lead to inaccurate variables."
      ],
      "metadata": {
        "id": "5A9fa4sszomY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'A': [1, 2, 2, 3, 4],\n",
        "        'B': ['x', 'y', 'y', 'z', 'z']}\n",
        "df = pd.DataFrame(data)\n",
        "print(df,'\\n')\n",
        "\n",
        "# detect duplicated rows\n",
        "print(df.duplicated(),'\\n')\n",
        "\n",
        "# getting rid of duplicates\n",
        "print(df.drop_duplicates(),'\\n')\n",
        "\n",
        "# getting rid of duplicates but keeping the last one\n",
        "print(df.drop_duplicates(keep = \"last\"),'\\n')\n",
        "\n",
        "# getting rid of duplicates in a specific column\n",
        "print(df.drop_duplicates(subset = [\"B\"]),'\\n')"
      ],
      "metadata": {
        "id": "Js0NM-3xzq3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3175e1-bc62-43b2-8384-20935700b39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   A  B\n",
            "0  1  x\n",
            "1  2  y\n",
            "2  2  y\n",
            "3  3  z\n",
            "4  4  z \n",
            "\n",
            "0    False\n",
            "1    False\n",
            "2     True\n",
            "3    False\n",
            "4    False\n",
            "dtype: bool \n",
            "\n",
            "   A  B\n",
            "0  1  x\n",
            "1  2  y\n",
            "3  3  z\n",
            "4  4  z \n",
            "\n",
            "   A  B\n",
            "0  1  x\n",
            "2  2  y\n",
            "3  3  z\n",
            "4  4  z \n",
            "\n",
            "   A  B\n",
            "0  1  x\n",
            "1  2  y\n",
            "3  3  z \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Renaming columns\n",
        "\n",
        "Data acquired from secondary sources can have column names that are long or difficult to deal with. Marketing datasets are no exception. It makes sense to properly rename columns at this stage if required."
      ],
      "metadata": {
        "id": "-RCs_5J4N4ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions.rename(columns = {'transaction_date': 'date', 'standard_cost': 'scost'}).columns"
      ],
      "metadata": {
        "id": "j1yFjvJkN3vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom classes for cleaning"
      ],
      "metadata": {
        "id": "i5MYgyse4AXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CleanRoutine:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def remove_missing_values(self):\n",
        "        self.data = self.data.dropna()\n",
        "        return self.data\n",
        "\n",
        "    def remove_duplicates(self):\n",
        "        self.data = self.data.drop_duplicates()\n",
        "        return self.data\n",
        "\n",
        "    def rename_columns(self, column_mapping):\n",
        "        self.data = self.data.rename(columns = column_mapping)\n",
        "        return self.data\n",
        "\n",
        "data = {'First Name': ['Alice', 'Bob', None, 'David'],\n",
        "        'Last Name': ['Smith', 'Johnson', 'Brown', None],\n",
        "        'Age': [25, 30, 22, 28]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# create an instance of the DataCleaner class and perform cleaning operations\n",
        "# step by step\n",
        "routine = CleanRoutine(df)\n",
        "routine.remove_missing_values()\n",
        "routine.remove_duplicates()\n",
        "routine.rename_columns({'First Name': 'FirstName', 'Last Name': 'LastName'})\n",
        "clean_data = routine.data\n",
        "\n",
        "print(\"\\nCleaned DataFrame:\")\n",
        "print(clean_data)\n"
      ],
      "metadata": {
        "id": "gpl-20rG4Eu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Transformation\n",
        "\n",
        "At this stage the main task is to figure out how to change certain inherent properties of the dataset that would allow us to create new information or subset information appropriately."
      ],
      "metadata": {
        "id": "JlN-4CMpEomC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing the shape\n",
        "\n",
        "Often we need to change the shape of the dataframe to \"tidy\" up the data. Tidy data principles promote consistency and simplicity in data organization, making data analysis more efficient and less error-prone.\n",
        "\n",
        "**Each Variable Forms a Column:** Each variable should have its own column in the dataset. This makes it clear what each column represents and allows for easy manipulation.\n",
        "\n",
        "**Each Observation Forms a Row:** Each observation (data point) should have its own row in the dataset. This ensures that each piece of information is clearly associated with a specific observation.\n",
        "\n",
        "**Each Type of Observational Unit Forms a Table:** Each type of data should be stored in its own separate table. Related data should be organized together, and separate tables can be linked if needed."
      ],
      "metadata": {
        "id": "QbQVJFqN8Oxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of data in wide format\n",
        "customer_info = pd.read_csv(\"https://raw.githubusercontent.com/pallavrouth/MarketingAnalytics/main/datasets/transaction_customerinfo.csv\")\n",
        "customer_info.head(n = 10)\n",
        "\n",
        "# changing the data from a wide to a long format\n",
        "customer_info_long = pd.melt(customer_info,\n",
        "                             id_vars = \"customer_id\",\n",
        "                             var_name = \"attribute\",\n",
        "                             value_name = \"value\")\n",
        "# print(customer_info_long.head(n = 10),'\\n')\n",
        "customer_info_long.sort_values(\"customer_id\").head(n = 10)"
      ],
      "metadata": {
        "id": "M_nimSrmGD-R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "df709e45-46d2-464b-9593-1cbe26f1bddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       customer_id              attribute                value\n",
              "11735            1                    DOB           1953-10-12\n",
              "35195            1               owns_car                  Yes\n",
              "27375            1         wealth_segment        Mass Customer\n",
              "15645            1                    age                 69.0\n",
              "5                1                   name    Laraine Medendorp\n",
              "3915             1                 gender               Female\n",
              "31285            1     deceased_indicator                    N\n",
              "19555            1              job_title  Executive Secretary\n",
              "39105            1                 tenure                   11\n",
              "23465            1  job_industry_category               Health"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a915198-3858-45a4-8bd9-4a5c37cdcd61\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>attribute</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11735</th>\n",
              "      <td>1</td>\n",
              "      <td>DOB</td>\n",
              "      <td>1953-10-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35195</th>\n",
              "      <td>1</td>\n",
              "      <td>owns_car</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27375</th>\n",
              "      <td>1</td>\n",
              "      <td>wealth_segment</td>\n",
              "      <td>Mass Customer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15645</th>\n",
              "      <td>1</td>\n",
              "      <td>age</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>name</td>\n",
              "      <td>Laraine Medendorp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3915</th>\n",
              "      <td>1</td>\n",
              "      <td>gender</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31285</th>\n",
              "      <td>1</td>\n",
              "      <td>deceased_indicator</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19555</th>\n",
              "      <td>1</td>\n",
              "      <td>job_title</td>\n",
              "      <td>Executive Secretary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39105</th>\n",
              "      <td>1</td>\n",
              "      <td>tenure</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23465</th>\n",
              "      <td>1</td>\n",
              "      <td>job_industry_category</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a915198-3858-45a4-8bd9-4a5c37cdcd61')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a915198-3858-45a4-8bd9-4a5c37cdcd61 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a915198-3858-45a4-8bd9-4a5c37cdcd61');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3f9adb33-5743-4e3d-9fd7-3d1db7d148f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f9adb33-5743-4e3d-9fd7-3d1db7d148f6')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3f9adb33-5743-4e3d-9fd7-3d1db7d148f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data manipulation\n",
        "\n",
        "This is arguably the most important aspect of data wrangling. This step involves manipulating the columns and/or rows of the existing data frame to either subset data or reorganize data or generate new columns or summarize the data in ways that are crucial for testing hypothesis or answering research questions.\n",
        "\n"
      ],
      "metadata": {
        "id": "DagCNJ82NslN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subsetting data\n",
        "\n",
        "We can subset data by (1) selecting certain columns and (2) by filtering rows that meet certain conditions"
      ],
      "metadata": {
        "id": "Wo0Epa972TGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Selecting colums"
      ],
      "metadata": {
        "id": "BIAgi42E5wsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting columns using '.loc' 'customer_id', 'transaction_date' 'product_id' 'list_price' 'order_status'\n",
        "# .loc[[row names]:[column names]]\n",
        "# for all rows use ':'\n",
        "transactions.loc[:,['transaction_date']].head() # note the difference between this and transactions.loc[:,'transaction_date'].head()\n",
        "# what products did a customer buy on a specific day and how much did they spend?\n",
        "transactions.loc[:,['customer_id','transaction_date','product_id','list_price','standard_cost']].head()\n",
        "# selecting a range of columns\n",
        "transactions.loc[:,'transaction_id':'transaction_date'].head() # notice that we do not supply a list\n",
        "# if I had to select the columns that had the word product how would I do it?\n",
        "columns = transactions.columns.to_list()\n",
        "mask = ['product' in col for col in columns]\n",
        "transactions.loc[:,mask]\n"
      ],
      "metadata": {
        "id": "nwW7UXiZOhwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Filtering rows"
      ],
      "metadata": {
        "id": "0AcN0Mk350yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# when you want to filter based on column that has numerical values\n",
        "mask = transactions.list_price > 1000 # good thing is you dont need to convert list price to a list\n",
        "transactions.loc[mask] # transactions.loc[mask,:] for consistency\n",
        "transactions.loc[lambda d: d.list_price > 1000,:]\n",
        "\n",
        "# when you want to filter based on column that has categorical values\n",
        "transactions.loc[lambda d: d.product_class == 'medium',:]\n",
        "# better to use .isin()\n",
        "transactions.loc[lambda d: d.product_class.isin(['medium']),:]\n",
        "transactions.loc[lambda d: d.product_class.isin(['low','medium']),:]\n",
        "\n",
        "# multiple conditions\n",
        "# satisfies both conditions - and\n",
        "transactions.loc[lambda d: (d.list_price > 1000) & (d.product_class.isin(['low','medium'])),:]\n",
        "print(transactions.loc[lambda d: (d.list_price > 1000) & (d.product_class.isin(['low','medium'])),:].shape)\n",
        "# satisfies any one condition - or\n",
        "transactions.loc[lambda d: (d.list_price > 1000) | (d.product_class.isin(['low','medium'])),:]\n",
        "print(transactions.loc[lambda d: (d.list_price > 1000) | (d.product_class.isin(['low','medium'])),:].shape)"
      ],
      "metadata": {
        "id": "QFWs1Y3i53rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reorganizing data\n",
        "\n",
        "We can reorganize data by sorting the data based on the values in one of the columns"
      ],
      "metadata": {
        "id": "2FBuIi6H_6G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what products did a customer buy on a specific day and how much did they spend?\n",
        "transactions_subset = transactions.loc[:,['customer_id','transaction_date','product_id','list_price','standard_cost']]\n",
        "transactions_organized = transactions_subset.sort_values(['customer_id'])\n",
        "transactions_organized_price = transactions_organized.sort_values(['list_price'], ascending = False)\n",
        "transactions_organized_price"
      ],
      "metadata": {
        "id": "k9ECvhGmADtt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "bf82ae82-01e8-432a-9c2a-15a06478fbd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       customer_id transaction_date  product_id  list_price standard_cost\n",
              "19109         2020       01/05/2017           3     2091.47       $388.92\n",
              "18170          690       04/07/2017           3     2091.47       $388.92\n",
              "6783          1133       24/02/2017           3     2091.47       $388.92\n",
              "16864         1492       17/12/2017           3     2091.47       $388.92\n",
              "3534           685       04/07/2017           3     2091.47       $388.92\n",
              "...            ...              ...         ...         ...           ...\n",
              "6169          1239       22/11/2017          19       12.01         $7.21\n",
              "5654          1892       04/01/2017           0       12.01         $7.21\n",
              "11988          101       26/07/2017           0       12.01         $7.21\n",
              "19291          150       16/10/2017          19       12.01         $7.21\n",
              "9583          1545       17/06/2017          19       12.01         $7.21\n",
              "\n",
              "[20000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a224d40d-404a-4736-b98f-a0d93c81708a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>transaction_date</th>\n",
              "      <th>product_id</th>\n",
              "      <th>list_price</th>\n",
              "      <th>standard_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19109</th>\n",
              "      <td>2020</td>\n",
              "      <td>01/05/2017</td>\n",
              "      <td>3</td>\n",
              "      <td>2091.47</td>\n",
              "      <td>$388.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18170</th>\n",
              "      <td>690</td>\n",
              "      <td>04/07/2017</td>\n",
              "      <td>3</td>\n",
              "      <td>2091.47</td>\n",
              "      <td>$388.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6783</th>\n",
              "      <td>1133</td>\n",
              "      <td>24/02/2017</td>\n",
              "      <td>3</td>\n",
              "      <td>2091.47</td>\n",
              "      <td>$388.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16864</th>\n",
              "      <td>1492</td>\n",
              "      <td>17/12/2017</td>\n",
              "      <td>3</td>\n",
              "      <td>2091.47</td>\n",
              "      <td>$388.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3534</th>\n",
              "      <td>685</td>\n",
              "      <td>04/07/2017</td>\n",
              "      <td>3</td>\n",
              "      <td>2091.47</td>\n",
              "      <td>$388.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6169</th>\n",
              "      <td>1239</td>\n",
              "      <td>22/11/2017</td>\n",
              "      <td>19</td>\n",
              "      <td>12.01</td>\n",
              "      <td>$7.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5654</th>\n",
              "      <td>1892</td>\n",
              "      <td>04/01/2017</td>\n",
              "      <td>0</td>\n",
              "      <td>12.01</td>\n",
              "      <td>$7.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11988</th>\n",
              "      <td>101</td>\n",
              "      <td>26/07/2017</td>\n",
              "      <td>0</td>\n",
              "      <td>12.01</td>\n",
              "      <td>$7.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19291</th>\n",
              "      <td>150</td>\n",
              "      <td>16/10/2017</td>\n",
              "      <td>19</td>\n",
              "      <td>12.01</td>\n",
              "      <td>$7.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9583</th>\n",
              "      <td>1545</td>\n",
              "      <td>17/06/2017</td>\n",
              "      <td>19</td>\n",
              "      <td>12.01</td>\n",
              "      <td>$7.21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a224d40d-404a-4736-b98f-a0d93c81708a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a224d40d-404a-4736-b98f-a0d93c81708a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a224d40d-404a-4736-b98f-a0d93c81708a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-20b814a1-a322-4edc-8442-ebd230f79737\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20b814a1-a322-4edc-8442-ebd230f79737')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-20b814a1-a322-4edc-8442-ebd230f79737 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating new data or editing existing data\n",
        "\n",
        "Sometimes we need to generate new data by combining information from existing data in the dataframe. At other times we need to edit existing data."
      ],
      "metadata": {
        "id": "-VBsElCVAxXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(transactions_subset.transaction_date.to_list()[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUgqZiVIA6Vm",
        "outputId": "ddcced07-e51e-4674-8369-b2f09f1cdfce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating new data"
      ],
      "metadata": {
        "id": "iOoItpvcDOtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# method 1\n",
        "transactions_subset_copy = transactions_subset.copy()\n",
        "transactions_subset_copy['list_price_100'] = transactions_subset['list_price'] / 100\n",
        "transactions_subset_copy\n",
        "\n",
        "# method 2 - preferred\n",
        "transactions_subset.assign(list_price_100 = lambda d: d.list_price / 100)\n",
        "\n",
        "# custom function to entire column\n",
        "import numpy as np\n",
        "def Max(x):\n",
        "  return np.nanmax(x)\n",
        "\n",
        "transactions_subset.assign(max_list_price = lambda d: Max(d.list_price))\n",
        "\n",
        "# method 3 - when you need to apply a custom function to each row of a column use 'apply' (safer option)\n",
        "def Transform(x):\n",
        "  step1 = x/100\n",
        "  step2 = round(step1,2)\n",
        "  return f\"The transformed value is {step2}.\"\n",
        "\n",
        "# apply a function to each row of the\n",
        "transactions_subset.assign(max_list_price = lambda d: d.list_price.apply(Transform))"
      ],
      "metadata": {
        "id": "-Hq5DHiqBpHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Special case - logic based data creation\n",
        "\n",
        "Sometimes we need to create new information based on whether it satisfies certain conditions. For example, indicator variables or dummy variables require using conditions or logic."
      ],
      "metadata": {
        "id": "1y9kOqfQT-Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# single condition\n",
        "transactions_subset.assign(ifelsecol = lambda d: np.where(d.list_price > 500,1,0))\n",
        "\n",
        "# multiple conditions\n",
        "transactions_subset.assign(ifelsecol = lambda d: np.where((d.list_price > 500) & (d.list_price < 3000),1,0))\n",
        "\n",
        "# matching conditions\n",
        "def match_condition(x):\n",
        "  if x > 0 and x <= 500: return \"cat1\"\n",
        "  elif x > 500 and x <= 1500: return \"cat2\"\n",
        "  else: return \"cat3\"\n",
        "\n",
        "transactions_subset.assign(cat_col = lambda d: d.list_price.apply(match_condition))\n",
        "transactions_subset_copy.cat_col.value_counts()"
      ],
      "metadata": {
        "id": "PKwAMhZ-UVta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Special case - One hot encoding"
      ],
      "metadata": {
        "id": "35pjwkOB4LE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Groupwise data creation\n",
        "\n",
        "Another popular special case of creating new data is when we have to edit information or create new data conditional on group membership. That is, we create create new variables using values within a group. This is true when the data has a heirarchical structure or has multiple level. This method is sometimes referred to split and apply."
      ],
      "metadata": {
        "id": "sXLoKkWqzTdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what is the cumulative amount spent by each customer over time?\n",
        "transactions_subset_copy_sorted = transactions_subset.sort_values('customer_id')\n",
        "transactions_subset_copy_gd = transactions_subset_copy_sorted.assign(cumsum_price = lambda d: d.groupby('customer_id')['list_price'].transform('cumsum'))\n",
        "transactions_subset_copy_gd"
      ],
      "metadata": {
        "id": "yn1_-puozS9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Editing existing information\n",
        "\n",
        "Sometimes we need to edit existing information. This usually involves type conversion or re-casting existing data in certain formats. This type of data creation is often categorized under 'cleaning' step discussed previously."
      ],
      "metadata": {
        "id": "LPFxBUgXDRPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting strings to floats/numeric\n",
        "print(type(transactions_subset.standard_cost.to_list()[0]))\n",
        "float('10.45')\n",
        "# float('$10.45') # error\n",
        "def toFloat(x):\n",
        "  if isinstance(x, str):\n",
        "    float_str = x.replace('$','').replace(',','')\n",
        "    return float(float_str)\n",
        "  else:\n",
        "    return x\n",
        "\n",
        "transactions_subset.assign(fstandard_cost = lambda d: d.standard_cost.apply(toFloat))\n",
        "\n",
        "# using astype in Pandas\n",
        "\n",
        "# converting strings to floats/numeric\n",
        "# print(type(transactions_subset.transaction_date.to_list()[0]))\n",
        "\n",
        "# frequent special case - taking care of date columns\n",
        "# transaction date is actually stored as string\n",
        "print(type(transactions_subset.transaction_date.to_list()[0]))\n",
        "# would be much better if it is stored as date type (which is unique to pandas)\n",
        "transactions_subset.assign(ftransaction_date = lambda d: pd.to_datetime(d.transaction_date))\n",
        "\n",
        "# why I prefer assign\n",
        "transactions_subset.assign(list_price_100 = lambda d: d.list_price / 100,\n",
        "                           ftransaction_date = lambda d: pd.to_datetime(d.transaction_date))\n"
      ],
      "metadata": {
        "id": "Pk1YVuYGDckt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another popular special case of creating new data is when we have to edit information or create new data conditional on group membership. That is, we create create new variables using values within a group. This is true when the data has a heirarchical structure or has multiple level. This method is sometimes referred to split and apply."
      ],
      "metadata": {
        "id": "gA2REkLCyRw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarizing data\n",
        "\n",
        "Sometimes we need to summarize the information from multiple rows and columns. This is particularly useful when we need to analyze the data to understand important trends. We will go more into depth in the next class."
      ],
      "metadata": {
        "id": "veaJJHQ513Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using the tuple notation -- different agg functions to different columns\n",
        "transactions_subset.groupby('customer_id', as_index = False).agg(sum_spend = ('list_price','sum'),\n",
        "                                                                 avg_spend = ('list_price','mean'),\n",
        "                                                                 ntransactions = ('transaction_date','nunique'))\n",
        "\n",
        "# using the dictionary notation -- different agg functions to the same column\n",
        "aggregations = {\n",
        "    'list_price': {\n",
        "        'sum_spend': 'sum',\n",
        "        'avg_spend': 'mean',\n",
        "    },\n",
        "    'transaction_date': {\n",
        "        'ntransactions': 'nunique'\n",
        "    }\n",
        "}\n",
        "\n",
        "aggregations = {\n",
        "    'list_price': ['sum','mean'],\n",
        "    'transaction_date': 'nunique'\n",
        "}\n",
        "\n",
        "transactions_subset.groupby('customer_id', as_index = False).agg(aggregations)"
      ],
      "metadata": {
        "id": "lh9sAueMx6PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method chaining\n",
        "\n",
        "Method chaining in Pandas is a technique that involves combining multiple DataFrame or Series methods in a single statement, without the need to create intermediate variables. This approach allows you to perform a sequence of data manipulation operations more concisely and makes your code more readable.\n",
        "\n",
        "Method chaining is possible due to the fact that most Pandas methods return a modified copy of the data, which means you can immediately apply another method on the result, and so on."
      ],
      "metadata": {
        "id": "Exb3QLQt3v_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1: select columns\n",
        "# step 2: arrange rows\n",
        "# step 3: filter rows\n",
        "# step 4: create new columns\n",
        "\n",
        "updated_data = (\n",
        "    transactions.loc[:,['customer_id','transaction_date','product_id','list_price','standard_cost']]\n",
        "      .sort_values(['customer_id'])\n",
        "      .loc[lambda d: d.list_price > 1000,:]\n",
        "      .assign(list_price_100 = lambda d: d.list_price / 100,\n",
        "              ftransaction_date = lambda d: pd.to_datetime(d.transaction_date))\n",
        ")\n",
        "\n",
        "updated_data.head()"
      ],
      "metadata": {
        "id": "DhDWZcnnjuqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation\n",
        "\n",
        "Data augmentation simply involves adding new data to the existing datasets. There are several key considerations when you consider merging multiple datasets.\n",
        "\n",
        "First, is what column would be used to merge the datasets. There must be a common column (also called 'keys') between the datasets before merging is attempted. Second, key consideration is how to should be merged. There are primary 4 important merging tactics - inner, outer, left and right. This [page](https://pandas.pydata.org/docs/dev/user_guide/merging.html) has helpful visuals on the principles behind these 4 types of merging process\n",
        "\n",
        "Data augmentation and data manipulation often goes hand in hand. Sometimes it makes sense to perform augmentation before manipulation. It really depends on what is more necessary."
      ],
      "metadata": {
        "id": "-a4vdE_H3s4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding common keys\n",
        "print(transactions.columns)\n",
        "print(transactions.shape)\n",
        "print(customer_info.columns)\n",
        "print(customer_info.shape)\n",
        "\n",
        "# how to merge -- left or inner are most common\n",
        "merged_data = transactions.merge(customer_info, how = 'left', on = 'customer_id')\n",
        "print(merged_data.columns)\n",
        "print(merged_data.shape)"
      ],
      "metadata": {
        "id": "2Os0lDsE38Oo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}